# -*- coding: utf-8 -*-
"""
Created on Thu Feb  4 23:09:20 2016

@author: Lingyu
"""
import csv
import numpy as np
import matplotlib.pyplot as plt
import glob
import os
import os.path
from skimage import feature
from sklearn.neighbors import KNeighborsClassifier
from sklearn.lda import LDA
from sklearn import svm
from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegressionCV

X=[]
y1=[]
y=[]

# get labels of training_set
with open('train.csv') as csvfile:
    reader=csv.DictReader(csvfile)
    for row in reader:
        y1.append(int(row['Prediction']))

# obtain the training_set       
file_lists=glob.glob('data/train/*')

for image in file_lists:
    #print image,'\n'
    c=os.path.basename(image).split(".")[0]
    d=int(c.split("_")[1])
    y.append(y1[d])
    im=plt.imread(image)
    #iim=im.reshape(1,512*512*3)
    im_mean=np.mean([im[:,:,0],im[:,:,1],im[:,:,2]],axis=0)
   
    lbp_image=[feature.local_binary_pattern(im_mean,8,5,method='uniform')]
    histogram=np.histogram(lbp_image,bins=540)[0] 
    X.append(histogram)
X=preprocessing.scale(X)    

# training a model
classifiers=[
           (svm.SVC(C=10**12, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False),"Support Vector Machine")
             ]

#Split your data into two partsâ€”80% for training and 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
i=0
for clf,name in classifiers:
    clf.fit(X_train,y_train)
    print accuracy_score(y_test,clf.predict(X_test))

#load the test data  
name=[]
name_value=[]
y_pred=[]
Test_set=[]

file_lists_test=glob.glob('data/test/*') 
for image in file_lists_test:
    c=os.path.basename(image)
    name.append(c)
    c=os.path.basename(image).split('.')[0]
    d=int(c.split("_")[1])
    name_value.append(d)
    im=plt.imread(image)
    im_mean=np.mean([im[:,:,0],im[:,:,1],im[:,:,2]],axis=0)
    lbp_image=[feature.local_binary_pattern(im_mean,8,5,method='uniform')]
    histogram=np.histogram(lbp_image,bins=540)[0] 
    Test_set.append(histogram)
Test_set=preprocessing.scale(Test_set)

indexes=[]
Test_sort=[]
name_sort=[]
indexes=sorted(name_value,key=lambda k: name_value[k])
for n in indexes:
    Test_sort.append(Test_set[n])
    name_sort.append(name[n])

y_pred=clf.predict(Test_sort)
with open('result05.csv','w') as csvfile:
    fieldnames=['Id','Prediction']
    writer=csv.DictWriter(csvfile,fieldnames=fieldnames)
    
    writer.writeheader()
    j=np.arange(0,len(y_pred),1)
    for i in j:
        writer.writerow({'Id':name_sort[i],'Prediction':y_pred[i]})
    
